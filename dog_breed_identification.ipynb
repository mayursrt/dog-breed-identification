{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dog-breed-identification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "119e9qVOzpMxisOu3N88wO3G9KyYJWIos",
      "authorship_tag": "ABX9TyN5oKuy2GhjOs2zZJKMgcOM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayursrt/dog-breed-identification/blob/main/dog_breed_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8rX78bLy4KB"
      },
      "source": [
        "# Dog Breed Identification\n",
        "This notebook builds an end-to-end multi-class image classifier using TensorFlow 2.x and TensorFlow Hub.\n",
        "\n",
        "1. Problem\n",
        "Identifying the breed of a dog given an image of a dog.\n",
        "\n",
        "When I'm sitting at the cafe and I take a photo of a dog, I want to know what breed of dog it is.\n",
        "\n",
        "2. Data\n",
        "The data we're using is from Kaggle's dog breed identification competition. You can get the data here:\n",
        "\n",
        "https://www.kaggle.com/c/dog-breed-identification/data\n",
        "\n",
        "3. Evaluation\n",
        "The evaluation is a file with prediction probabilities for each dog breed of each test image.\n",
        "\n",
        "https://www.kaggle.com/c/dog-breed-identification/overview/evaluation\n",
        "\n",
        "4. Features\n",
        "Some information about the data:\n",
        "\n",
        "* We're dealing with images (unstructured data) so it's probably best we use deep learning/transfer learning.\n",
        "* There are 120 breeds of dogs (this means there are 120 different classes).\n",
        "* There are around 10,000+ images in the training set (these images have labels).\n",
        "* There are around 10,000+ images in the test set (these images have no labels, because we'll want to predict them).\n",
        "\n",
        "\n",
        "### Getting the workspace ready\n",
        "First Import all the packages needed for the task:\n",
        "* TensorFlow 2.x\n",
        "* TensorFlow Hub\n",
        "\n",
        "Also check if you're using a GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy1JhpE1CYmJ"
      },
      "source": [
        "# import packages and check their versions\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "print('TensorFlow version:', tf.__version__)\n",
        "print('TensorFlow Hub version:', hub.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl8Ra5cuC80R"
      },
      "source": [
        "# check GPU availability\n",
        "print(\"GPU\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-9ZZHrGFz7y"
      },
      "source": [
        "**NOTE:** This project will not be able to run if there is no GPU available. If using Google Colab, Goto Runtime > Change Runtime Type > Select GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAHTj40EEK0E"
      },
      "source": [
        "### Getting our data ready (turning into Tensors)\n",
        "With all machine learning models, our data has to be in numerical format. So that's what we'll be doing first. Turning our images into Tensors (numerical representations).\n",
        "\n",
        "Let's start by accessing our data and checking out the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCCmSIEMQgSS"
      },
      "source": [
        "# Checkout the labels of the data\n",
        "import pandas as pd\n",
        "labels_csv = pd.read_csv(\"drive/MyDrive/Dog Breed Identification using Tensorflow/data/labels.csv\")\n",
        "print(labels_csv.describe())\n",
        "print(labels_csv.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K5a6tTLRuUh"
      },
      "source": [
        "labels_csv['breed'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_UheqH7SOsq"
      },
      "source": [
        "labels_csv['breed'].value_counts().plot.bar(figsize=(20, 10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaG24IkgScxL"
      },
      "source": [
        "# median labels per breed to get distribution of data\n",
        "labels_csv['breed'].value_counts().median()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdGTETfMS7JI"
      },
      "source": [
        " # View an Image\n",
        " from IPython.display import Image\n",
        " Image('drive/MyDrive/Dog Breed Identification using Tensorflow/data/train/0021f9ceb3235effd7fcde7f7538ed62.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERNBTE4mzZPN"
      },
      "source": [
        "\n",
        "\n",
        "### Getting images and their labels\n",
        "Get the list of all image file pathnames."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trFT1f3BUKYE"
      },
      "source": [
        "# create pathnames for image ids\n",
        "filenames = ['drive/MyDrive/Dog Breed Identification using Tensorflow/data/train/' + fname + '.jpg' for fname in labels_csv ['id']]\n",
        "filenames[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0PM-Qn90CkE"
      },
      "source": [
        "# check if the number of filenames match the number of actual image files(this can be caused by incomplete upload of the files)\n",
        "import os\n",
        "if len(os.listdir('drive/MyDrive/Dog Breed Identification using Tensorflow/data/train/')) == len(filenames):\n",
        "  print('Filenames match actual amount of files..!!! you can proceed.')\n",
        "else:\n",
        "  print('Filenames do not match the actual amount of files..!! please try and reupload the data directory')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90HKodcs2MZa"
      },
      "source": [
        "Preparing the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_le2jSvr2yTn"
      },
      "source": [
        "import numpy as np\n",
        "# transforming labels so that they can be used.\n",
        "labels = np.array(labels_csv['breed'])  ## can also use labels = labels_csv['breed'].to_numpy()\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1o5MTy334qx"
      },
      "source": [
        "#check length of labels\n",
        "len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHBOLf744GUB"
      },
      "source": [
        "# see if the number of labels match the length of filenames\n",
        "if len(labels) == len(filenames):\n",
        "  print('Filenames match actual amount of files..!!! you can proceed.')\n",
        "else:\n",
        "  print('Filenames do not match the actual amount of files..!! please try and reupload the data directory')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViQrIuT_4w1L"
      },
      "source": [
        "#find unique label values\n",
        "unique_breeds = np.unique(labels)\n",
        "unique_breeds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG67j0HN6t0C"
      },
      "source": [
        "#len of unique breeds\n",
        "len(unique_breeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsujnD_U5F_S"
      },
      "source": [
        "#turning a label into a boolean array\n",
        "print(labels[0])\n",
        "labels[0] == unique_breeds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o79R0RdV5yKl"
      },
      "source": [
        "# likewise turning all labels in boolean array\n",
        "labels_bool = [labels == unique_breeds for labels in labels]\n",
        "labels_bool[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZMZvWTZ7jvW"
      },
      "source": [
        "# turning boolean array into integers #maybe not needed\n",
        "\n",
        "print(labels[0])\n",
        "print(np.where(unique_breeds == labels[0]))\n",
        "print(labels_bool[0].argmax())\n",
        "print(labels_bool[0].astype(int))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9Xnsz4npsYB"
      },
      "source": [
        "### Creating validation set \n",
        "since we do not have validation set in our dataset, we need to create one so that we can run validation tests on the validation set.\n",
        "\n",
        "we can use `train_test_split` for this job"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98jUNJ3rtBlc"
      },
      "source": [
        "# split into X and y\n",
        "\n",
        "X = filenames\n",
        "y = labels_bool"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF2Z-7_Vt6zx"
      },
      "source": [
        "Starting off with ~1000 images since we need to reduce time taken for running the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5sfeD_Ou5a6"
      },
      "source": [
        "# set number of images used for experimenting\n",
        "# if using jupyter notebook, set images number direct to a value\n",
        "#NUM_IMAGES = 1000\n",
        "# OR\n",
        "# we can also use slider to set the number of images and increase them on the go if you are using Google Colab.\n",
        "NUM_IMAGES = 1000 #@param {type:\"slider\", min:1000, max:10222, step:500}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bmvdvdkwTIJ"
      },
      "source": [
        "# spliting data into train and validation set\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split them into training and validation of total size NUM_IMAGES\n",
        "np.random.seed(42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES], y[:NUM_IMAGES], test_size=0.2)\n",
        "len(X_train), len(y_train), len(X_val), len(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsst7GzE08ie"
      },
      "source": [
        "### Preprocessing Images(turning Images into Tensors)\n",
        "Since we might need to reuse the functionality of preprocessing the data, we need to create a function so that it is easy to reuse it.\n",
        "\n",
        "\n",
        "To preprocess our images into Tensors we're going to write a function which does a few things:\n",
        "\n",
        "1. Take an image filepath as input\n",
        "1. Use TensorFlow to read the file and save it to a variable, `image`\n",
        "1. Turn our `image` (a jpg) into Tensors\n",
        "1. Normalize our image (convert color channel values from from 0-255 to 0-1).\n",
        "1. Resize the `image` to be a shape of (224, 224)\n",
        "1. Return the modified `image`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY48B7N63mXN"
      },
      "source": [
        "# lets look how image looks in a numpy array vs in a tensor\n",
        "from matplotlib.pyplot import imread\n",
        "image = imread(filenames[45])\n",
        "# image in form of a numpy array\n",
        "image[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH8SB4is4CL4"
      },
      "source": [
        "#image in form of a tensor\n",
        "tf.constant(image)[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFOj7pj51mvi"
      },
      "source": [
        "# creating the function\n",
        "\n",
        "# Define image size\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# write function\n",
        "def process_image(image_path, img_size=IMG_SIZE):\n",
        "  \"\"\"\n",
        "  Takes an image file path and turns the image into a Tensor.\n",
        "  \"\"\"\n",
        "  # Read in an image file\n",
        "  image = tf.io.read_file(image_path)\n",
        "  # turn jpg image to numerical tensor with 3 color channels RGB\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  # convert colour channel values from 0-255 to 0-1 values\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  # resize image\n",
        "  image =  tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
        "  # return image\n",
        "\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI0ychxc65xC"
      },
      "source": [
        "### Turning data into batches \n",
        "\n",
        "Why turn our data into batches?\n",
        "\n",
        "Let's say you're trying to process 10,000+ images in one go... they all might not fit into memory.\n",
        "\n",
        "So that's why we do about 32 (this is the batch size) images at a time (you can manually adjust the batch size if need be).\n",
        "\n",
        "In order to use TensorFlow effectively, we need our data in the form of Tensor tuples which look like this: `(image, label)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LFYFasyWsKQ"
      },
      "source": [
        "# Create func to return a tuple (image, label)\n",
        "\n",
        "def get_image_label(image_path, label):\n",
        "  \"\"\"\n",
        "  Takes an image file path name and the assosciated label,\n",
        "  processes the image and reutrns a typle of (image, label).\n",
        "  \"\"\"\n",
        "  image = process_image(image_path)\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YELZipjXmeW"
      },
      "source": [
        "# Create function to turn all the data into batches.\n",
        "\n",
        "# Define batch size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def create_data_batches(X, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
        "  \"\"\"\n",
        "  Creates batches of data out of image (X) and label (y) pairs.\n",
        "  Shuffles the data if it's training data but doesn't shuffle if it's validation data.\n",
        "  Also accepts test data as input (no labels).\n",
        "  \"\"\"\n",
        "  # if the data is a test dataset, we will not have labels\n",
        "  if test_data:\n",
        "    print('Creating test data batches...')\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X)))\n",
        "    data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  # if the data is validation data, we don't need to shuffle it\n",
        "  elif valid_data:\n",
        "    print('Creating valid data batches...')\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
        "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  # else training data \n",
        "  else:\n",
        "    print('Creating train data batches...')\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
        "    # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n",
        "    data = data.shuffle(buffer_size=len(X))\n",
        "\n",
        "    # Create (image, label) tuples (this also turns the iamge path into a preprocessed image)\n",
        "    data = data.map(get_image_label)\n",
        "\n",
        "    # Turn the training data into batches\n",
        "    data_batch = data.batch(BATCH_SIZE)\n",
        "  return data_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px9LUcc6Y3ZX"
      },
      "source": [
        "# create training and validation data batches\n",
        "\n",
        "train_data = create_data_batches(X_train, y_train)\n",
        "valid_data = create_data_batches(X_val, y_val, valid_data=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLwQ-GAvgZIn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}